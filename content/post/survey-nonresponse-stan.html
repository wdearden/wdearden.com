---
title: 'Survey Nonresponse: Partial Identification in Stan'
author: Will Dearden
date: '2020-05-22'
slug: survey-nonresponse-stan
categories: []
tags:
  - R
  - Stan
image:
  caption: ''
  focal_point: ''
---



<p>Let’s say you send out a survey to 100 random people with a single yes/no question. 80 people response and 60 of those 80 people say yes and the other 20 say no. The classic question in statistics is: what percent of the population would say yes to this question if they all responded? The first approach would be to say 60 of the 80 responded said yes so we would estimate that the population “yes rate” would be 75%. But that assumes that other 20 who didn’t respond would say yes at the same rate as the people who responded. That’s a stretch of an assumption. The question could be “Do you have a cell phone?” and the 20 who didn’t respond don’t have a phone at all.</p>
<p>This leads us to another question: what can we say if we make no assumptions about the people who didn’t respond? We know that 60 of the 100 people did say yes and 20 said no. If we don’t make any assumptions about the other 20 then all we can say is that anywhere between 0 and 20 of them would have said yes if they had responded. So our estimate for the population “yes rate” is anywhere between 60 and 80 percent.</p>
<p>This approach to statistics is called <a href="https://scholar.harvard.edu/files/tamer/files/pie.pdf">partial identification</a> and was pioneered by econometrics professor <a href="https://en.wikipedia.org/wiki/Charles_F._Manski">Charles Manski</a>. In this post I’m going to formalize some of the mathematics of the situation described above. Then I’m going to fit a model of this situation and get estimates of the lower and upper bounds given sampling error. To do this I’m going to use the probabilistic programming language <a href="https://mc-stan.org/">Stan</a> and call Stan from R.</p>
<div id="the-math-of-partial-identification" class="section level2">
<h2>The math of partial identification</h2>
<p>Let’s say <span class="math inline">\(y\)</span> is a binary variable which represents the answer to the survey question and <span class="math inline">\(r\)</span> is a binary variable which represents whether someone responds to the question or not. We are interested in estimating <span class="math inline">\(P(y = 1)\)</span>. That is, what is the probability that the answer to the survey question is “yes” for a random person in the population? We can break up <span class="math inline">\(P(y = 1)\)</span> based on whether they would respond to the survey or not using the <a href="https://en.wikipedia.org/wiki/Law_of_total_probability">law of total probability</a>.</p>
<p><span class="math display">\[P(y=1) = P(y=1|r=1) * P(r=1) + P(y=1|r=0) * P(r=0)\]</span></p>
<p>To simplify the notation, we can replace of the probabilities with parameters. To summarize them:</p>
<p><span class="math display">\[\begin{align*}
\theta &amp;= P(y = 1) \\
\theta_{yr} &amp;= P(y = 1|r=1) \\
\theta_r &amp;= P(r = 1) \\
\theta_{ynr} &amp;= P(y = 1|r = 0) \\
\end{align*}\]</span></p>
<p>Then we can replace those variables in the equation and use the fact that all we know about <span class="math inline">\(\theta_{ynr}\)</span> (proportion of nonrespondents who would respond yes) is that <span class="math inline">\(0 \leq \theta_{ynr} \leq 1\)</span> to get bounds on <span class="math inline">\(\theta\)</span>.</p>
<p><span class="math display">\[\theta = \theta_{yr} * \theta_r + \theta_{ynr} * (1 - \theta_r) \]</span>
<span class="math display">\[\theta_{yr} * \theta_r \leq \theta \leq \theta_{yr} * \theta_r + (1 - \theta_r)\]</span></p>
</div>
<div id="generative-model" class="section level2">
<h2>Generative model</h2>
<p>Let <span class="math inline">\(N\)</span> be the number of people we send the survey to, <span class="math inline">\(r\)</span> be the number of people who respond, and <span class="math inline">\(y\)</span> be the number of people who say yes. Then we can write a model for how these data were generated based on the unknown parameters above. We will assume a uniform prior for <span class="math inline">\(\theta_r\)</span> and <span class="math inline">\(\theta_{yr}\)</span>. We will assume that <span class="math inline">\(y\)</span> and <span class="math inline">\(r\)</span> are generated by a binomial distribution. And we will specify <span class="math inline">\(\theta_{lower}\)</span> and <span class="math inline">\(\theta_{upper}\)</span> based on the inequality above.</p>
<p><span class="math display">\[\begin{align*}
\theta_r &amp;\sim Uniform(0, 1) \\
\theta_{yr} &amp;\sim Uniform(0, 1) \\
r|\theta_r &amp;\sim Binomial(N, \theta_r) \\
y|\theta_{yr} &amp;\sim Binomial(r, \theta_{yr}) \\
\theta_{lower} &amp;= \theta_r*\theta_{yr} \\
\theta_{upper} &amp;= \theta_r*\theta_{yr} + (1 - \theta_r)
\end{align*}\]</span></p>
</div>
<div id="stan-file" class="section level2">
<h2>Stan file</h2>
<p>The nice thing about Stan is that this mathematical model translates directly to Stan code.</p>
<pre class="stan"><code>data {
  int&lt;lower=0&gt; N;
  int&lt;lower=0,upper=N&gt; r;
  int&lt;lower=0,upper=r&gt; y;
}

parameters {
  real&lt;lower=0,upper=1&gt; theta_r;
  real&lt;lower=0,upper=1&gt; theta_yr;
}

model {
  r ~ binomial(N, theta_r);
  y ~ binomial(r, theta_yr);
}

generated quantities {
  real&lt;lower=0,upper=1&gt; theta_lower;
  real&lt;lower=0,upper=1&gt; theta_upper;
  theta_lower = theta_r*theta_yr;
  theta_upper = theta_lower + (1 - theta_r);
}</code></pre>
<p>Since we didn’t specify a prior distribution for <span class="math inline">\(\theta_r\)</span> and <span class="math inline">\(\theta_{yr}\)</span>, Stan automatically chose a uniform distribution.</p>
<pre class="r"><code>library(rstan)
library(bayesplot)
library(ggplot2)
library(data.table)</code></pre>
<pre class="r"><code>N &lt;- 100
r &lt;- 80
y &lt;- 60
theta_yr_point &lt;- y/r
theta_lower_point &lt;- y/N
theta_upper_point &lt;- y/N + 1 - r/N
survey_data &lt;- list(N = N, r = r, y = y)
fit &lt;- sampling(nonresponse, survey_data)</code></pre>
<pre class="r"><code>fit</code></pre>
<pre><code>## Inference for Stan model: 3af63e94b6c9efbd0049b265a8a1db73.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##               mean se_mean   sd    2.5%    25%    50%    75%  97.5% n_eff
## theta_r       0.79    0.00 0.04    0.71   0.77   0.79   0.82   0.87  3085
## theta_yr      0.74    0.00 0.05    0.65   0.71   0.75   0.78   0.83  2777
## theta_lower   0.59    0.00 0.05    0.49   0.56   0.59   0.62   0.68  2768
## theta_upper   0.80    0.00 0.04    0.72   0.77   0.80   0.82   0.87  2820
## lp__        -99.51    0.02 1.00 -102.23 -99.87 -99.21 -98.79 -98.54  1705
##             Rhat
## theta_r        1
## theta_yr       1
## theta_lower    1
## theta_upper    1
## lp__           1
## 
## Samples were drawn using NUTS(diag_e) at Fri May 22 14:11:27 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<pre class="r"><code>mcmc_areas(fit, regex_pars = &#39;^theta&#39;) + theme(text = element_text(size = 18))</code></pre>
<p><img src="/post/survey-nonresponse-stan_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>mcmc_scatter(fit, pars = c(&#39;theta_lower&#39;, &#39;theta_upper&#39;), alpha = 0.1) + theme(text = element_text(size = 18))</code></pre>
<p><img src="/post/survey-nonresponse-stan_files/figure-html/unnamed-chunk-4-2.png" width="672" /></p>
<p>Another way to show our posterior is to plot 50 draws from the posterior of our estimated range for <span class="math inline">\(\theta\)</span> and for <span class="math inline">\(\theta_{yr}\)</span>. Plus, we’ll show our “point estimate” for the interval in red.</p>
<pre class="r"><code>num_iter &lt;- 50
DT &lt;- as.data.table(rstan::extract(fit, c(&#39;theta_lower&#39;, &#39;theta_upper&#39;, &#39;theta_yr&#39;)))
DT &lt;- DT[1:num_iter][, point := FALSE]
pointDT &lt;- data.table(
    theta_lower = theta_lower_point,
    theta_upper = theta_upper_point,
    theta_yr = theta_yr_point,
    point = TRUE
)
DT &lt;- rbindlist(list(DT, pointDT))
DT &lt;- DT[order(-theta_yr)]
DT[, iter := 1:nrow(DT)]

ggplot(DT, aes(xmin = theta_lower, xmax = theta_upper, x = theta_yr, y = iter, color = point)) +
    geom_errorbarh() +
    geom_point(size = 0.8) +
    theme_default() +
    scale_color_manual(values = c(&#39;black&#39;, &#39;red&#39;)) +
    guides(color = FALSE) +
    theme(
        text = element_text(size = 18),
        axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.title.y = element_blank()
    )</code></pre>
<p><img src="/post/survey-nonresponse-stan_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
